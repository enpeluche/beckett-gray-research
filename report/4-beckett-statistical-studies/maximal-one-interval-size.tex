\subsection{Taille des intervalles de longueur maximale de bit à $1$}
Nous étudions la taille des intervalles de longueur maximale afin de déterminer s'il est possible d'en déduire une propriété.
Par exemple, si nous constatons qu'il n'y a jamais plus de $k$ bits consécutifs à $1$ dans un même code, cela nous permettrait
de couper les branches plus rapidement. En étudiant les données disponibles, on constate que l'on a une borne inférieure et
supérieure pour le plus grand nombre de bit consécutif à $1$ dans les cas respectifs où $n=5$, $n=6$ et $n=7$. On le connaît à
$\llbracket 5, 7 \rrbracket$ pour $n = 5$. On l'estime à $\llbracket 6, 10 \rrbracket$ pour $n = 6$. On l'estime grossièrement
à $\llbracket 9, 11 \rrbracket$ pour $n = 7$. \\

On peut alors formuler des conjectures sur l'existence de longueur de borne inférieur et supérieur d'intervalles de longueur
maximale contenant des bits à $1$ consécutifs de taille minimale et maximale.\\

Il existerait toujours au moins un intervalle de longueur $5$ dans le cas $n=5$, de longueur $6$ dans le cas $n=6$ et $9$ dans
le cas $n=7$, on aurait jamais plus de $7$ bit à $1$ consécutifs pour $n=5$, jamais plus de $10$ pour $n=6$ et jamais plus de
$11$ pour $n=7$. En acceptant cette conjecture cela nous permettrait de développer une heuristique qui coupe l'intervalle si il
y a seulement $k$ sommets restant et qu'il est impossible d'avoir $k$ fois de suite le même bit à $1$, ou qui passe à $0$ si on
observe plus de $K$ bits consécutifs à $1$. Nous ne le l'implémenterons pas par manque de temps. On peut cependant penser que
dans le cas de l'existence d'une borne inférieure, on pourrait couper des branches sur la fin de l'arbre et donc couper peu de
solutions, ce qui rendrait l'heuristique négligeable par rapport à son coût d'implémentation, quand à prendre les intervalles
maximales, elle réduit légèrement le temps d'exécution.
